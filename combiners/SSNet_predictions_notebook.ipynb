{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2128fff-6647-439e-aeed-3d6036759c90",
   "metadata": {},
   "source": [
    "# SSNet Predictions\n",
    "\n",
    "This notebook is meant for hands-on interaction with the code and data used in `SSNet_predictions.py`. Annotations explaining the general functioning of each section and the other modules they reference are provided. Similar notebooks may be added for individual models and combiners in the future. Note that the code shown here does not necessarily reflect the content of the script version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70050e31-7d4b-4f80-82f1-0ce7d54b72bc",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "365f9f09-7fa7-4a5d-982f-92c3a77f3e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is master file that runs all the three combiners proposed in the paper. \\nUse following snippet to run all the three combiners: python SSNet_predictions.py\\nPlease note that this code has tensorflow dependencies.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "==================================================LICENSING TERMS==================================================\n",
    "This code and data was developed by employees of the National Institute of Standards and Technology (NIST), an agency of the Federal Government. Pursuant to title 17 United States Code Section 105, works of NIST employees are not subject to copyright protection in the United States and are considered to be in the public domain. The code and data is provided by NIST as a public service and is expressly provided \"AS IS.\" NIST MAKES NO WARRANTY OF ANY KIND, EXPRESS, IMPLIED OR STATUTORY, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTY OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT AND DATA ACCURACY. NIST does not warrant or make any representations regarding the use of the data or the results thereof, including but not limited to the correctness, accuracy, reliability or usefulness of the data. NIST SHALL NOT BE LIABLE AND YOU HEREBY RELEASE NIST FROM LIABILITY FOR ANY INDIRECT, CONSEQUENTIAL, SPECIAL, OR INCIDENTAL DAMAGES (INCLUDING DAMAGES FOR LOSS OF BUSINESS PROFITS, BUSINESS INTERRUPTION, LOSS OF BUSINESS INFORMATION, AND THE LIKE), WHETHER ARISING IN TORT, CONTRACT, OR OTHERWISE, ARISING FROM OR RELATING TO THE DATA (OR THE USE OF OR INABILITY TO USE THIS DATA), EVEN IF NIST HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n",
    "To the extent that NIST may hold copyright in countries other than the United States, you are hereby granted the non-exclusive irrevocable and unconditional right to print, publish, prepare derivative works and distribute the NIST data, in any medium, or authorize others to do so on your behalf, on a royalty-free basis throughout the world.\n",
    "You may improve, modify, and create derivative works of the code or the data or any portion of the code or the data, and you may copy and distribute such modifications or works. Modified works should carry a notice stating that you changed the code or the data and should note the date and nature of any such change. Please explicitly acknowledge the National Institute of Standards and Technology as the source of the code or the data: Citation recommendations are provided below. Permission to use this code and data is contingent upon your acceptance of the terms of this agreement and upon your providing appropriate acknowledgments of NIST's creation of the code and data.\n",
    "Paper Title:\n",
    "    SSNet: a Sagittal Stratum-inspired Neural Network Framework for Sentiment Analysis\n",
    "SSNet authors and developers:\n",
    "    Apostol Vassilev:\n",
    "        Affiliation: National Institute of Standards and Technology\n",
    "        Email: apostol.vassilev@nist.gov\n",
    "    Munawar Hasan:\n",
    "        Affiliation: National Institute of Standards and Technology\n",
    "        Email: munawar.hasan@nist.gov\n",
    "    Jin Honglan\n",
    "        Affiliation: National Institute of Standards and Technology\n",
    "        Email: honglan.jin@nist.gov\n",
    "====================================================================================================================\n",
    "'''\n",
    "\n",
    "'''\n",
    "This is master file that runs all the three combiners proposed in the paper. \n",
    "Use following snippet to run all the three combiners: python SSNet_predictions.py\n",
    "Please note that this code has tensorflow dependencies.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92fd944-e689-4daa-a782-915db10f206e",
   "metadata": {},
   "source": [
    "## Imports/Dependencies\n",
    "\n",
    "TensorFlow is the main machine learning framework used to implement, train, and apply the models. Pandas and NumPy are used for general data preprocessing and manipulation. Components from Matplotlib/Pyplot and IPython which are absent from `SSNet_predictions.py` are utilized here to provide enhanced interactivity and visualization. Functions from the following scripts (corresponding to the combiner models described in the paper) are imported:\n",
    " - `SSNet_Neural_Network.py`\n",
    " - `SSNet_Bayesian_Decision.py`\n",
    " - `SSNet_Heuristic_Hybrid.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae03c1f-dd3f-472d-bfcd-1b4c389fe4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import JSON\n",
    "import itertools\n",
    "\n",
    "from SSNet_Neural_Network import nn, wrap_nn\n",
    "from SSNet_Bayesian_Decision import bayesian_decision\n",
    "from SSNet_Heuristic_Hybrid import heuristic_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f451afe-7bd7-4850-80d9-20e722514919",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_5ktr = 'imdb_train_5k.csv'\n",
    "model_a_tr = 'model_1_5ktrain.csv'\n",
    "model_b_tr = 'model_2_5ktrain.csv'\n",
    "# model_c_tr = 'model_3_bert_result_train_5k.csv'\n",
    "# model_d_tr = 'model_4_use_result_train_5k.csv'\n",
    "model_c_tr = 'model_3_5ktrain.csv'\n",
    "model_d_tr = 'model_4_5ktrain.csv'\n",
    "\n",
    "model_a_te = 'model_1_25ktest.csv'\n",
    "model_b_te = 'model_2_25ktest.csv'\n",
    "# model_c_te = 'model_3_bert_result_test_25k.csv'\n",
    "# model_d_te = 'model_4_use_result_test_25k.csv'\n",
    "model_c_te = 'model_3_25ktest.csv'\n",
    "model_d_te = 'model_4_25ktest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67dc15d-759a-44c6-996c-1e7552d3ba81",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1effdb21-842a-4141-ad5a-3ae4f9e5777a",
   "metadata": {},
   "source": [
    "### Training Dict Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5e7a31-3838-4e40-be2c-1836d48fd708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dict_threshold(split):\n",
    "    training_dict = dict()\n",
    "\n",
    "    if split == \"5K\":\n",
    "        training_dict[\"5K\"] = [\n",
    "            [model_a_tr, model_b_tr, model_c_tr, model_d_tr], [\n",
    "                model_a_te, model_b_te, model_c_te, model_d_te]\n",
    "        ]\n",
    "        \n",
    "    return training_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd0ec35-8af4-45ab-9b4b-faf4a40fde83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '2'), ('1', '3'), ('1', '4'), ('2', '3'), ('2', '4'), ('3', '4')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.combinations('1234', 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284fb2fc-2920-406e-9c66-d3bffdc2baf0",
   "metadata": {},
   "source": [
    "### Training Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d4c530b-93cd-4717-83cd-bcc81a712bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "model_{1,2,3,4}": [
        [
         "model_1_5ktrain.csv",
         "model_2_5ktrain.csv",
         "model_3_5ktrain.csv",
         "model_4_5ktrain.csv"
        ],
        [
         "model_1_25ktest.csv",
         "model_2_25ktest.csv",
         "model_3_25ktest.csv",
         "model_4_25ktest.csv"
        ]
       ],
       "model_{1,2,3}": [
        [
         "model_1_5ktrain.csv",
         "model_2_5ktrain.csv",
         "model_3_5ktrain.csv"
        ],
        [
         "model_1_25ktest.csv",
         "model_2_25ktest.csv",
         "model_3_25ktest.csv"
        ]
       ],
       "model_{1,2,4}": [
        [
         "model_1_5ktrain.csv",
         "model_2_5ktrain.csv",
         "model_4_5ktrain.csv"
        ],
        [
         "model_1_25ktest.csv",
         "model_2_25ktest.csv",
         "model_4_25ktest.csv"
        ]
       ],
       "model_{1,2}": [
        [
         "model_1_5ktrain.csv",
         "model_2_5ktrain.csv"
        ],
        [
         "model_1_25ktest.csv",
         "model_2_25ktest.csv"
        ]
       ],
       "model_{1,3,4}": [
        [
         "model_1_5ktrain.csv",
         "model_3_5ktrain.csv",
         "model_4_5ktrain.csv"
        ],
        [
         "model_1_25ktest.csv",
         "model_3_25ktest.csv",
         "model_4_25ktest.csv"
        ]
       ],
       "model_{1,3}": [
        [
         "model_1_5ktrain.csv",
         "model_3_5ktrain.csv"
        ],
        [
         "model_1_25ktest.csv",
         "model_3_25ktest.csv"
        ]
       ],
       "model_{1,4}": [
        [
         "model_1_5ktrain.csv",
         "model_4_5ktrain.csv"
        ],
        [
         "model_1_25ktest.csv",
         "model_4_25ktest.csv"
        ]
       ],
       "model_{2,3,4}": [
        [
         "model_2_5ktrain.csv",
         "model_3_5ktrain.csv",
         "model_4_5ktrain.csv"
        ],
        [
         "model_2_25ktest.csv",
         "model_3_25ktest.csv",
         "model_4_25ktest.csv"
        ]
       ],
       "model_{2,3}": [
        [
         "model_2_5ktrain.csv",
         "model_3_5ktrain.csv"
        ],
        [
         "model_2_25ktest.csv",
         "model_3_25ktest.csv"
        ]
       ],
       "model_{2,4}": [
        [
         "model_2_5ktrain.csv",
         "model_4_5ktrain.csv"
        ],
        [
         "model_2_25ktest.csv",
         "model_4_25ktest.csv"
        ]
       ],
       "model_{3,4}": [
        [
         "model_3_5ktrain.csv",
         "model_4_5ktrain.csv"
        ],
        [
         "model_3_25ktest.csv",
         "model_4_25ktest.csv"
        ]
       ]
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_training_dict(split):\n",
    "    training_dict = dict()\n",
    "#     Store a running list of model combinations\n",
    "#     included_models = []\n",
    "    if split == \"5K\":\n",
    "#         Loop through integers 2 to 4 (inclusive); the number of component models in each combination\n",
    "        for r in range(2, 5):\n",
    "#             Generate combinations of model indices (without repetition)\n",
    "            for c in itertools.combinations(map(str, range(1, 5)), r):\n",
    "                training_dict['model_{{{}}}'.format(','.join(c))] = [\n",
    "#                     Generate the file names corresponding to each model's output on both the training and testing data\n",
    "                    [f'model_{m}_{n}{t}.csv' for m in c] for n, t in [\n",
    "                        ('5k', 'train'),\n",
    "                        ('25k', 'test')\n",
    "                    ]\n",
    "                ]\n",
    "\n",
    "    return training_dict\n",
    "\n",
    "# Test the function\n",
    "JSON(get_training_dict(\"5K\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e7f04a-645d-4344-8712-e2146481938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_25k_list = list()\n",
    "data_dir = 'models/train'\n",
    "for file_name in os.listdir(f'../{data_dir}/pos'):\n",
    "    if file_name != '.DS_Store':\n",
    "        imdb_25k_list.append([file_name, str(1)])\n",
    "\n",
    "for file_name in os.listdir(f'../{data_dir}/neg'):\n",
    "    if file_name != '.DS_Store':\n",
    "        imdb_25k_list.append([file_name, str(0)])\n",
    "\n",
    "SAMPLE_SPLIT = [\"5K\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789679a-0be1-4a61-8351-9cfefd494764",
   "metadata": {},
   "source": [
    "## Train Predictors\n",
    "\n",
    "Train the predictors and return the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a72be80b-83e6-4c09-b353-c7c44f75bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predictor(**kwargs):\n",
    "    for split in SAMPLE_SPLIT:\n",
    "        print(\"Sample Split: \", split)\n",
    "        imdb_list = list()\n",
    "        training_dict = None\n",
    "        training_dict_threshold = None\n",
    "\n",
    "        if split == \"5K\":\n",
    "            df_imdb_tr = pd.read_csv(imdb_5ktr)\n",
    "            for index in df_imdb_tr.index:\n",
    "                file_name = str(df_imdb_tr['file'][index])\n",
    "                label = int(df_imdb_tr['label'][index])\n",
    "                imdb_list.append([file_name, str(label)])\n",
    "\n",
    "            random.shuffle(imdb_list)\n",
    "            training_dict = get_training_dict(split)\n",
    "            training_dict_threshold = get_training_dict_threshold(split)\n",
    "\n",
    "            random.shuffle(imdb_list)\n",
    "            training_dict = get_training_dict(split)\n",
    "            training_dict_threshold = get_training_dict_threshold(split)\n",
    "\n",
    "\n",
    "        acc_dict_nn = dict()\n",
    "        acc_dict_bdc = dict()\n",
    "\n",
    "        for k, v in training_dict.items():\n",
    "\n",
    "            tr_list = list()\n",
    "            te_list = list()\n",
    "\n",
    "            for i in range(len(v[0])):\n",
    "                df = pd.read_csv(v[0][i])\n",
    "                df_dict = dict()\n",
    "\n",
    "                for idx in df.index:\n",
    "                    file_name = str(df['file'][idx])\n",
    "                    proba = float(df['prob'][idx])\n",
    "                    df_dict[file_name] = proba\n",
    "\n",
    "                tr_list.append(df_dict)\n",
    "\n",
    "            for i in range(len(v[1])):\n",
    "                df = pd.read_csv(v[1][i])\n",
    "                df_dict = dict()\n",
    "\n",
    "                for idx in df.index:\n",
    "                    file_name = str(df['file'][idx])\n",
    "                    proba = float(df['prob'][idx])\n",
    "                    df_dict[file_name] = proba\n",
    "\n",
    "                te_list.append(df_dict)\n",
    "\n",
    "\n",
    "            assert len(tr_list) == len(te_list), \"train and test samples mismatch ....\"\n",
    "            tr_acc = -1.\n",
    "            te_acc = -1.\n",
    "            while True:\n",
    "                tr_acc, te_acc, weights = wrap_nn(tr_list=tr_list, imdb_tr_list=imdb_list,\n",
    "                    te_list=te_list, imdb_te_list=imdb_25k_list, **kwargs)\n",
    "\n",
    "                if weights[0][0] == 0. or weights[0][1] == 0.:\n",
    "                    print(\"bad event ...., training again\")\n",
    "                    print(\"\\t\" +k)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            acc_dict_nn[k] = [tr_acc, te_acc]\n",
    "\n",
    "            acc_dict_bdc[k] = bayesian_decision(tr_list=tr_list, imdb_tr_list=imdb_list,\n",
    "                                             te_list=te_list, imdb_te_list=imdb_25k_list)\n",
    "\n",
    "\n",
    "        for k, v in training_dict_threshold.items():\n",
    "            tr_list = list()\n",
    "            te_list = list()\n",
    "\n",
    "            for i in range(len(v[0])):\n",
    "                df = pd.read_csv(v[0][i])\n",
    "                df_dict = dict()\n",
    "\n",
    "                for idx in df.index:\n",
    "                    file_name = str(df['file'][idx])\n",
    "                    proba = float(df['prob'][idx])\n",
    "                    df_dict[file_name] = proba\n",
    "\n",
    "                tr_list.append(df_dict)\n",
    "\n",
    "            for i in range(len(v[1])):\n",
    "                df = pd.read_csv(v[1][i])\n",
    "                df_dict = dict()\n",
    "\n",
    "                for idx in df.index:\n",
    "                    file_name = str(df['file'][idx])\n",
    "                    proba = float(df['prob'][idx])\n",
    "                    df_dict[file_name] = proba\n",
    "\n",
    "                te_list.append(df_dict)\n",
    "\n",
    "        hh_dict = heuristic_hybrid(tr_list=tr_list, imdb_tr_list=imdb_list,\n",
    "                        te_list=te_list, imdb_te_list=imdb_25k_list)\n",
    "\n",
    "        nn_metrics = []\n",
    "        #print(\"Training Complete: \")\n",
    "        print(\"Neural Network Combiner: \")\n",
    "        for k, v in acc_dict_nn.items():\n",
    "            print(\"\\t\" +k +\": training accuracy = \" +str(v[0]) + \", test accuracy = \" +str(v[1]))\n",
    "            nn_metrics.append(v)\n",
    "            \n",
    "        bdr_metrics = []\n",
    "        print(\"\\n\")\n",
    "        print(\"Bayesian Decision Rule Combiner: \")\n",
    "        for k, v in acc_dict_bdc.items():\n",
    "            print(\"\\t\" +k)\n",
    "            for i, j in v.items():\n",
    "                print(\"\\t\\t\" +i +\": training accuracy = \" +str(j[0]) +\", test accuracy = \" +str(j[1]))\n",
    "            bdr_metrics.append(v)\n",
    "        \n",
    "        hh_metrics = []\n",
    "        print(\"\\n\")\n",
    "        print(\"Heuristic-Hybrid Combiner: \")\n",
    "        for k, v in hh_dict.items():\n",
    "            print(\"Base:\", k)\n",
    "            for index in range(len(v)):\n",
    "                print(\"\\t\\t\", v[index])\n",
    "            print(\"\\n\")\n",
    "            hh_metrics.append(v)\n",
    "            \n",
    "        return nn_metrics, bdr_metrics, hh_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918602a-a859-4ce2-a561-22a23da37641",
   "metadata": {},
   "source": [
    "## Result Aggregation\n",
    "\n",
    "Runs the predictor training script and displays the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67de7f66-2340-4a1b-87b2-ab30cb5e646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = []\n",
    "durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4654280-ac9a-4727-baf2-b71801645c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[120.70206046104431, 109.29466986656189, 142.6429591178894, 117.84209322929382]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744b0186-3e61-4480-af1d-dae2e324488b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Split:  5K\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2}\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,3}\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2,3}\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "Neural Network Combiner: \n",
      "\tmodel_{1,2}: training accuracy = 90.75999855995178, test accuracy = 90.57600000000001\n",
      "\tmodel_{1,3}: training accuracy = 93.27999949455261, test accuracy = 93.60000000000001\n",
      "\tmodel_{1,4}: training accuracy = 90.0600016117096, test accuracy = 89.89200000000001\n",
      "\tmodel_{2,3}: training accuracy = 93.48000288009644, test accuracy = 93.66\n",
      "\tmodel_{2,4}: training accuracy = 91.07999801635742, test accuracy = 91.01599999999999\n",
      "\tmodel_{3,4}: training accuracy = 93.26000213623047, test accuracy = 93.568\n",
      "\tmodel_{1,2,3}: training accuracy = 93.76000165939331, test accuracy = 93.888\n",
      "\tmodel_{1,2,4}: training accuracy = 91.24000072479248, test accuracy = 91.244\n",
      "\tmodel_{1,3,4}: training accuracy = 93.66000294685364, test accuracy = 93.768\n",
      "\tmodel_{2,3,4}: training accuracy = 93.4000015258789, test accuracy = 93.74\n",
      "\tmodel_{1,2,3,4}: training accuracy = 93.80000233650208, test accuracy = 93.71199999999999\n",
      "\n",
      "\n",
      "Bayesian Decision Rule Combiner: \n",
      "\tmodel_{1,2}\n",
      "\t\tmax: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\t\tavg: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\t\tsum: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\tmodel_{1,3}\n",
      "\t\tmax: training accuracy = 93.7, test accuracy = 93.512\n",
      "\t\tavg: training accuracy = 93.7, test accuracy = 93.512\n",
      "\t\tsum: training accuracy = 93.7, test accuracy = 93.512\n",
      "\tmodel_{1,4}\n",
      "\t\tmax: training accuracy = 90.24, test accuracy = 89.812\n",
      "\t\tavg: training accuracy = 90.24, test accuracy = 89.812\n",
      "\t\tsum: training accuracy = 90.24, test accuracy = 89.812\n",
      "\tmodel_{2,3}\n",
      "\t\tmax: training accuracy = 93.04, test accuracy = 93.508\n",
      "\t\tavg: training accuracy = 93.04, test accuracy = 93.508\n",
      "\t\tsum: training accuracy = 93.04, test accuracy = 93.508\n",
      "\tmodel_{2,4}\n",
      "\t\tmax: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\t\tavg: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\t\tsum: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\tmodel_{3,4}\n",
      "\t\tmax: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\t\tavg: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\t\tsum: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\tmodel_{1,2,3}\n",
      "\t\tmax: training accuracy = 93.36, test accuracy = 93.616\n",
      "\t\tavg: training accuracy = 92.64, test accuracy = 92.864\n",
      "\t\tsum: training accuracy = 92.64, test accuracy = 92.864\n",
      "\t\tmaj: training accuracy = 92.2, test accuracy = 92.144\n",
      "\tmodel_{1,2,4}\n",
      "\t\tmax: training accuracy = 91.3, test accuracy = 91.18\n",
      "\t\tavg: training accuracy = 90.86, test accuracy = 91.06400000000001\n",
      "\t\tsum: training accuracy = 90.86, test accuracy = 91.06400000000001\n",
      "\t\tmaj: training accuracy = 90.60000000000001, test accuracy = 90.668\n",
      "\tmodel_{1,3,4}\n",
      "\t\tmax: training accuracy = 93.17999999999999, test accuracy = 93.144\n",
      "\t\tavg: training accuracy = 92.2, test accuracy = 92.252\n",
      "\t\tsum: training accuracy = 92.2, test accuracy = 92.252\n",
      "\t\tmaj: training accuracy = 91.84, test accuracy = 91.724\n",
      "\tmodel_{2,3,4}\n",
      "\t\tmax: training accuracy = 92.82000000000001, test accuracy = 93.33200000000001\n",
      "\t\tavg: training accuracy = 92.86, test accuracy = 92.896\n",
      "\t\tsum: training accuracy = 92.86, test accuracy = 92.896\n",
      "\t\tmaj: training accuracy = 92.47999999999999, test accuracy = 92.528\n",
      "\tmodel_{1,2,3,4}\n",
      "\t\tmax: training accuracy = 93.02, test accuracy = 93.364\n",
      "\t\tavg: training accuracy = 92.80000000000001, test accuracy = 92.84400000000001\n",
      "\t\tsum: training accuracy = 92.80000000000001, test accuracy = 92.84400000000001\n",
      "\n",
      "\n",
      "Heuristic-Hybrid Combiner: \n",
      "Base: model_{1}\n",
      "\t\t {'tr_acc': 90.44, 'te_acc': 90.064, 'th': 0.92}\n",
      "\t\t {'tr_acc': 93.08, 'te_acc': 92.624, 'th': 0.95}\n",
      "\t\t {'tr_acc': 89.8, 'te_acc': 89.44800000000001, 'th': 0.89}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.86, 'te_acc': 93.28, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.88, 'te_acc': 92.88, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.88, 'te_acc': 92.88, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.62, 'te_acc': 92.524, 'th': 0.99}\n",
      "\n",
      "\n",
      "Base: model_{2}\n",
      "\t\t {'tr_acc': 90.28, 'te_acc': 90.076, 'th': 0.82}\n",
      "\t\t {'tr_acc': 92.72, 'te_acc': 92.708, 'th': 0.97}\n",
      "\t\t {'tr_acc': 90.9, 'te_acc': 90.672, 'th': 0.84}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 93.02, 'te_acc': 93.144, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.32, 'te_acc': 92.376, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.32, 'te_acc': 92.376, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.06, 'te_acc': 91.988, 'th': 0.97}\n",
      "\n",
      "\n",
      "Base: model_{3}\n",
      "\t\t {'tr_acc': 93.36, 'te_acc': 93.416, 'th': 0.83}\n",
      "\t\t {'tr_acc': 93.38, 'te_acc': 93.352, 'th': 0.83}\n",
      "\t\t {'tr_acc': 93.0, 'te_acc': 93.116, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.36, 'te_acc': 93.34, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.428, 'th': 0.76}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.428, 'th': 0.76}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.41199999999999, 'th': 0.76}\n",
      "\n",
      "\n",
      "Base: model_{4}\n",
      "\t\t {'tr_acc': 89.78, 'te_acc': 89.676, 'th': 0.94}\n",
      "\t\t {'tr_acc': 90.66, 'te_acc': 90.436, 'th': 0.93}\n",
      "\t\t {'tr_acc': 92.74, 'te_acc': 92.572, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.12, 'te_acc': 93.128, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.56, 'te_acc': 92.56400000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.56, 'te_acc': 92.56400000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.2, 'te_acc': 92.032, 'th': 0.99}\n",
      "\n",
      "\n",
      "Sample Split:  5K\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2}\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{2,3,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "Neural Network Combiner: \n",
      "\tmodel_{1,2}: training accuracy = 90.71999788284302, test accuracy = 90.57600000000001\n",
      "\tmodel_{1,3}: training accuracy = 93.30000281333923, test accuracy = 93.596\n",
      "\tmodel_{1,4}: training accuracy = 90.03999829292297, test accuracy = 89.912\n",
      "\tmodel_{2,3}: training accuracy = 93.48000288009644, test accuracy = 93.632\n",
      "\tmodel_{2,4}: training accuracy = 91.03999733924866, test accuracy = 91.008\n",
      "\tmodel_{3,4}: training accuracy = 93.26000213623047, test accuracy = 93.57600000000001\n",
      "\tmodel_{1,2,3}: training accuracy = 93.80000233650208, test accuracy = 93.864\n",
      "\tmodel_{1,2,4}: training accuracy = 91.28000140190125, test accuracy = 91.276\n",
      "\tmodel_{1,3,4}: training accuracy = 93.68000030517578, test accuracy = 93.76400000000001\n",
      "\tmodel_{2,3,4}: training accuracy = 93.4000015258789, test accuracy = 93.652\n",
      "\tmodel_{1,2,3,4}: training accuracy = 93.77999901771545, test accuracy = 93.72399999999999\n",
      "\n",
      "\n",
      "Bayesian Decision Rule Combiner: \n",
      "\tmodel_{1,2}\n",
      "\t\tmax: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\t\tavg: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\t\tsum: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\tmodel_{1,3}\n",
      "\t\tmax: training accuracy = 93.7, test accuracy = 93.512\n",
      "\t\tavg: training accuracy = 93.7, test accuracy = 93.512\n",
      "\t\tsum: training accuracy = 93.7, test accuracy = 93.512\n",
      "\tmodel_{1,4}\n",
      "\t\tmax: training accuracy = 90.24, test accuracy = 89.812\n",
      "\t\tavg: training accuracy = 90.24, test accuracy = 89.812\n",
      "\t\tsum: training accuracy = 90.24, test accuracy = 89.812\n",
      "\tmodel_{2,3}\n",
      "\t\tmax: training accuracy = 93.04, test accuracy = 93.508\n",
      "\t\tavg: training accuracy = 93.04, test accuracy = 93.508\n",
      "\t\tsum: training accuracy = 93.04, test accuracy = 93.508\n",
      "\tmodel_{2,4}\n",
      "\t\tmax: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\t\tavg: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\t\tsum: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\tmodel_{3,4}\n",
      "\t\tmax: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\t\tavg: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\t\tsum: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\tmodel_{1,2,3}\n",
      "\t\tmax: training accuracy = 93.36, test accuracy = 93.616\n",
      "\t\tavg: training accuracy = 92.64, test accuracy = 92.864\n",
      "\t\tsum: training accuracy = 92.64, test accuracy = 92.864\n",
      "\t\tmaj: training accuracy = 92.2, test accuracy = 92.144\n",
      "\tmodel_{1,2,4}\n",
      "\t\tmax: training accuracy = 91.3, test accuracy = 91.18\n",
      "\t\tavg: training accuracy = 90.86, test accuracy = 91.06400000000001\n",
      "\t\tsum: training accuracy = 90.86, test accuracy = 91.06400000000001\n",
      "\t\tmaj: training accuracy = 90.60000000000001, test accuracy = 90.668\n",
      "\tmodel_{1,3,4}\n",
      "\t\tmax: training accuracy = 93.17999999999999, test accuracy = 93.144\n",
      "\t\tavg: training accuracy = 92.2, test accuracy = 92.252\n",
      "\t\tsum: training accuracy = 92.2, test accuracy = 92.252\n",
      "\t\tmaj: training accuracy = 91.84, test accuracy = 91.724\n",
      "\tmodel_{2,3,4}\n",
      "\t\tmax: training accuracy = 92.82000000000001, test accuracy = 93.33200000000001\n",
      "\t\tavg: training accuracy = 92.86, test accuracy = 92.896\n",
      "\t\tsum: training accuracy = 92.86, test accuracy = 92.896\n",
      "\t\tmaj: training accuracy = 92.47999999999999, test accuracy = 92.528\n",
      "\tmodel_{1,2,3,4}\n",
      "\t\tmax: training accuracy = 93.02, test accuracy = 93.364\n",
      "\t\tavg: training accuracy = 92.80000000000001, test accuracy = 92.84400000000001\n",
      "\t\tsum: training accuracy = 92.80000000000001, test accuracy = 92.84400000000001\n",
      "\n",
      "\n",
      "Heuristic-Hybrid Combiner: \n",
      "Base: model_{1}\n",
      "\t\t {'tr_acc': 90.44, 'te_acc': 90.064, 'th': 0.92}\n",
      "\t\t {'tr_acc': 93.08, 'te_acc': 92.624, 'th': 0.95}\n",
      "\t\t {'tr_acc': 89.8, 'te_acc': 89.44800000000001, 'th': 0.89}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.86, 'te_acc': 93.28, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.88, 'te_acc': 92.88, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.88, 'te_acc': 92.88, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.62, 'te_acc': 92.524, 'th': 0.99}\n",
      "\n",
      "\n",
      "Base: model_{2}\n",
      "\t\t {'tr_acc': 90.28, 'te_acc': 90.076, 'th': 0.82}\n",
      "\t\t {'tr_acc': 92.72, 'te_acc': 92.708, 'th': 0.97}\n",
      "\t\t {'tr_acc': 90.9, 'te_acc': 90.672, 'th': 0.84}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 93.02, 'te_acc': 93.144, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.32, 'te_acc': 92.376, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.32, 'te_acc': 92.376, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.06, 'te_acc': 91.988, 'th': 0.97}\n",
      "\n",
      "\n",
      "Base: model_{3}\n",
      "\t\t {'tr_acc': 93.36, 'te_acc': 93.416, 'th': 0.83}\n",
      "\t\t {'tr_acc': 93.38, 'te_acc': 93.352, 'th': 0.83}\n",
      "\t\t {'tr_acc': 93.0, 'te_acc': 93.116, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.36, 'te_acc': 93.34, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.428, 'th': 0.76}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.428, 'th': 0.76}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.41199999999999, 'th': 0.76}\n",
      "\n",
      "\n",
      "Base: model_{4}\n",
      "\t\t {'tr_acc': 89.78, 'te_acc': 89.676, 'th': 0.94}\n",
      "\t\t {'tr_acc': 90.66, 'te_acc': 90.436, 'th': 0.93}\n",
      "\t\t {'tr_acc': 92.74, 'te_acc': 92.572, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.12, 'te_acc': 93.128, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.56, 'te_acc': 92.56400000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.56, 'te_acc': 92.56400000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.2, 'te_acc': 92.032, 'th': 0.99}\n",
      "\n",
      "\n",
      "Sample Split:  5K\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,3}\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{3,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2,3,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "Neural Network Combiner: \n",
      "\tmodel_{1,2}: training accuracy = 90.70000052452087, test accuracy = 90.57600000000001\n",
      "\tmodel_{1,3}: training accuracy = 93.30000281333923, test accuracy = 93.596\n",
      "\tmodel_{1,4}: training accuracy = 90.03999829292297, test accuracy = 89.888\n",
      "\tmodel_{2,3}: training accuracy = 93.45999956130981, test accuracy = 93.664\n",
      "\tmodel_{2,4}: training accuracy = 91.10000133514404, test accuracy = 91.012\n",
      "\tmodel_{3,4}: training accuracy = 93.2200014591217, test accuracy = 93.596\n",
      "\tmodel_{1,2,3}: training accuracy = 93.77999901771545, test accuracy = 93.848\n",
      "\tmodel_{1,2,4}: training accuracy = 91.28000140190125, test accuracy = 91.25999999999999\n",
      "\tmodel_{1,3,4}: training accuracy = 93.66000294685364, test accuracy = 93.76\n",
      "\tmodel_{2,3,4}: training accuracy = 93.4000015258789, test accuracy = 93.708\n",
      "\tmodel_{1,2,3,4}: training accuracy = 93.80000233650208, test accuracy = 93.708\n",
      "\n",
      "\n",
      "Bayesian Decision Rule Combiner: \n",
      "\tmodel_{1,2}\n",
      "\t\tmax: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\t\tavg: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\t\tsum: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\tmodel_{1,3}\n",
      "\t\tmax: training accuracy = 93.7, test accuracy = 93.512\n",
      "\t\tavg: training accuracy = 93.7, test accuracy = 93.512\n",
      "\t\tsum: training accuracy = 93.7, test accuracy = 93.512\n",
      "\tmodel_{1,4}\n",
      "\t\tmax: training accuracy = 90.24, test accuracy = 89.812\n",
      "\t\tavg: training accuracy = 90.24, test accuracy = 89.812\n",
      "\t\tsum: training accuracy = 90.24, test accuracy = 89.812\n",
      "\tmodel_{2,3}\n",
      "\t\tmax: training accuracy = 93.04, test accuracy = 93.508\n",
      "\t\tavg: training accuracy = 93.04, test accuracy = 93.508\n",
      "\t\tsum: training accuracy = 93.04, test accuracy = 93.508\n",
      "\tmodel_{2,4}\n",
      "\t\tmax: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\t\tavg: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\t\tsum: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\tmodel_{3,4}\n",
      "\t\tmax: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\t\tavg: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\t\tsum: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\tmodel_{1,2,3}\n",
      "\t\tmax: training accuracy = 93.36, test accuracy = 93.616\n",
      "\t\tavg: training accuracy = 92.64, test accuracy = 92.864\n",
      "\t\tsum: training accuracy = 92.64, test accuracy = 92.864\n",
      "\t\tmaj: training accuracy = 92.2, test accuracy = 92.144\n",
      "\tmodel_{1,2,4}\n",
      "\t\tmax: training accuracy = 91.3, test accuracy = 91.18\n",
      "\t\tavg: training accuracy = 90.86, test accuracy = 91.06400000000001\n",
      "\t\tsum: training accuracy = 90.86, test accuracy = 91.06400000000001\n",
      "\t\tmaj: training accuracy = 90.60000000000001, test accuracy = 90.668\n",
      "\tmodel_{1,3,4}\n",
      "\t\tmax: training accuracy = 93.17999999999999, test accuracy = 93.144\n",
      "\t\tavg: training accuracy = 92.2, test accuracy = 92.252\n",
      "\t\tsum: training accuracy = 92.2, test accuracy = 92.252\n",
      "\t\tmaj: training accuracy = 91.84, test accuracy = 91.724\n",
      "\tmodel_{2,3,4}\n",
      "\t\tmax: training accuracy = 92.82000000000001, test accuracy = 93.33200000000001\n",
      "\t\tavg: training accuracy = 92.86, test accuracy = 92.896\n",
      "\t\tsum: training accuracy = 92.86, test accuracy = 92.896\n",
      "\t\tmaj: training accuracy = 92.47999999999999, test accuracy = 92.528\n",
      "\tmodel_{1,2,3,4}\n",
      "\t\tmax: training accuracy = 93.02, test accuracy = 93.364\n",
      "\t\tavg: training accuracy = 92.80000000000001, test accuracy = 92.84400000000001\n",
      "\t\tsum: training accuracy = 92.80000000000001, test accuracy = 92.84400000000001\n",
      "\n",
      "\n",
      "Heuristic-Hybrid Combiner: \n",
      "Base: model_{1}\n",
      "\t\t {'tr_acc': 90.44, 'te_acc': 90.064, 'th': 0.92}\n",
      "\t\t {'tr_acc': 93.08, 'te_acc': 92.624, 'th': 0.95}\n",
      "\t\t {'tr_acc': 89.8, 'te_acc': 89.44800000000001, 'th': 0.89}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.86, 'te_acc': 93.28, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.88, 'te_acc': 92.88, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.88, 'te_acc': 92.88, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.62, 'te_acc': 92.524, 'th': 0.99}\n",
      "\n",
      "\n",
      "Base: model_{2}\n",
      "\t\t {'tr_acc': 90.28, 'te_acc': 90.076, 'th': 0.82}\n",
      "\t\t {'tr_acc': 92.72, 'te_acc': 92.708, 'th': 0.97}\n",
      "\t\t {'tr_acc': 90.9, 'te_acc': 90.672, 'th': 0.84}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 93.02, 'te_acc': 93.144, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.32, 'te_acc': 92.376, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.32, 'te_acc': 92.376, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.06, 'te_acc': 91.988, 'th': 0.97}\n",
      "\n",
      "\n",
      "Base: model_{3}\n",
      "\t\t {'tr_acc': 93.36, 'te_acc': 93.416, 'th': 0.83}\n",
      "\t\t {'tr_acc': 93.38, 'te_acc': 93.352, 'th': 0.83}\n",
      "\t\t {'tr_acc': 93.0, 'te_acc': 93.116, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.36, 'te_acc': 93.34, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.428, 'th': 0.76}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.428, 'th': 0.76}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.41199999999999, 'th': 0.76}\n",
      "\n",
      "\n",
      "Base: model_{4}\n",
      "\t\t {'tr_acc': 89.78, 'te_acc': 89.676, 'th': 0.94}\n",
      "\t\t {'tr_acc': 90.66, 'te_acc': 90.436, 'th': 0.93}\n",
      "\t\t {'tr_acc': 92.74, 'te_acc': 92.572, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.12, 'te_acc': 93.128, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.56, 'te_acc': 92.56400000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.56, 'te_acc': 92.56400000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.2, 'te_acc': 92.032, 'th': 0.99}\n",
      "\n",
      "\n",
      "Sample Split:  5K\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2}\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "bad event ...., training again\n",
      "\tmodel_{1,2,3,4}\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "25000 25000\n",
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy'])\n",
      "Neural Network Combiner: \n",
      "\tmodel_{1,2}: training accuracy = 90.74000120162964, test accuracy = 90.572\n",
      "\tmodel_{1,3}: training accuracy = 93.30000281333923, test accuracy = 93.596\n",
      "\tmodel_{1,4}: training accuracy = 90.0600016117096, test accuracy = 89.884\n",
      "\tmodel_{2,3}: training accuracy = 93.48000288009644, test accuracy = 93.636\n",
      "\tmodel_{2,4}: training accuracy = 90.92000126838684, test accuracy = 91.0\n",
      "\tmodel_{3,4}: training accuracy = 93.26000213623047, test accuracy = 93.592\n",
      "\tmodel_{1,2,3}: training accuracy = 93.80000233650208, test accuracy = 93.904\n",
      "\tmodel_{1,2,4}: training accuracy = 91.28000140190125, test accuracy = 91.264\n",
      "\tmodel_{1,3,4}: training accuracy = 93.68000030517578, test accuracy = 93.768\n",
      "\tmodel_{2,3,4}: training accuracy = 93.36000084877014, test accuracy = 93.692\n",
      "\tmodel_{1,2,3,4}: training accuracy = 93.80000233650208, test accuracy = 93.67999999999999\n",
      "\n",
      "\n",
      "Bayesian Decision Rule Combiner: \n",
      "\tmodel_{1,2}\n",
      "\t\tmax: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\t\tavg: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\t\tsum: training accuracy = 90.75999999999999, test accuracy = 90.324\n",
      "\tmodel_{1,3}\n",
      "\t\tmax: training accuracy = 93.7, test accuracy = 93.512\n",
      "\t\tavg: training accuracy = 93.7, test accuracy = 93.512\n",
      "\t\tsum: training accuracy = 93.7, test accuracy = 93.512\n",
      "\tmodel_{1,4}\n",
      "\t\tmax: training accuracy = 90.24, test accuracy = 89.812\n",
      "\t\tavg: training accuracy = 90.24, test accuracy = 89.812\n",
      "\t\tsum: training accuracy = 90.24, test accuracy = 89.812\n",
      "\tmodel_{2,3}\n",
      "\t\tmax: training accuracy = 93.04, test accuracy = 93.508\n",
      "\t\tavg: training accuracy = 93.04, test accuracy = 93.508\n",
      "\t\tsum: training accuracy = 93.04, test accuracy = 93.508\n",
      "\tmodel_{2,4}\n",
      "\t\tmax: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\t\tavg: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\t\tsum: training accuracy = 90.92, test accuracy = 91.10000000000001\n",
      "\tmodel_{3,4}\n",
      "\t\tmax: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\t\tavg: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\t\tsum: training accuracy = 92.66, test accuracy = 92.92399999999999\n",
      "\tmodel_{1,2,3}\n",
      "\t\tmax: training accuracy = 93.36, test accuracy = 93.616\n",
      "\t\tavg: training accuracy = 92.64, test accuracy = 92.864\n",
      "\t\tsum: training accuracy = 92.64, test accuracy = 92.864\n",
      "\t\tmaj: training accuracy = 92.2, test accuracy = 92.144\n",
      "\tmodel_{1,2,4}\n",
      "\t\tmax: training accuracy = 91.3, test accuracy = 91.18\n",
      "\t\tavg: training accuracy = 90.86, test accuracy = 91.06400000000001\n",
      "\t\tsum: training accuracy = 90.86, test accuracy = 91.06400000000001\n",
      "\t\tmaj: training accuracy = 90.60000000000001, test accuracy = 90.668\n",
      "\tmodel_{1,3,4}\n",
      "\t\tmax: training accuracy = 93.17999999999999, test accuracy = 93.144\n",
      "\t\tavg: training accuracy = 92.2, test accuracy = 92.252\n",
      "\t\tsum: training accuracy = 92.2, test accuracy = 92.252\n",
      "\t\tmaj: training accuracy = 91.84, test accuracy = 91.724\n",
      "\tmodel_{2,3,4}\n",
      "\t\tmax: training accuracy = 92.82000000000001, test accuracy = 93.33200000000001\n",
      "\t\tavg: training accuracy = 92.86, test accuracy = 92.896\n",
      "\t\tsum: training accuracy = 92.86, test accuracy = 92.896\n",
      "\t\tmaj: training accuracy = 92.47999999999999, test accuracy = 92.528\n",
      "\tmodel_{1,2,3,4}\n",
      "\t\tmax: training accuracy = 93.02, test accuracy = 93.364\n",
      "\t\tavg: training accuracy = 92.80000000000001, test accuracy = 92.84400000000001\n",
      "\t\tsum: training accuracy = 92.80000000000001, test accuracy = 92.84400000000001\n",
      "\n",
      "\n",
      "Heuristic-Hybrid Combiner: \n",
      "Base: model_{1}\n",
      "\t\t {'tr_acc': 90.44, 'te_acc': 90.064, 'th': 0.92}\n",
      "\t\t {'tr_acc': 93.08, 'te_acc': 92.624, 'th': 0.95}\n",
      "\t\t {'tr_acc': 89.8, 'te_acc': 89.44800000000001, 'th': 0.89}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 93.18, 'te_acc': 93.27600000000001, 'th': 0.97}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 91.072, 'th': 0.95}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.84, 'te_acc': 92.784, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.86, 'te_acc': 93.28, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.88, 'te_acc': 92.88, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.88, 'te_acc': 92.88, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.62, 'te_acc': 92.524, 'th': 0.99}\n",
      "\n",
      "\n",
      "Base: model_{2}\n",
      "\t\t {'tr_acc': 90.28, 'te_acc': 90.076, 'th': 0.82}\n",
      "\t\t {'tr_acc': 92.72, 'te_acc': 92.708, 'th': 0.97}\n",
      "\t\t {'tr_acc': 90.9, 'te_acc': 90.672, 'th': 0.84}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.408, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 91.14, 'te_acc': 90.924, 'th': 0.95}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 92.7, 'te_acc': 92.892, 'th': 0.98}\n",
      "\t\t {'tr_acc': 93.02, 'te_acc': 93.144, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.32, 'te_acc': 92.376, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.32, 'te_acc': 92.376, 'th': 0.97}\n",
      "\t\t {'tr_acc': 92.06, 'te_acc': 91.988, 'th': 0.97}\n",
      "\n",
      "\n",
      "Base: model_{3}\n",
      "\t\t {'tr_acc': 93.36, 'te_acc': 93.416, 'th': 0.83}\n",
      "\t\t {'tr_acc': 93.38, 'te_acc': 93.352, 'th': 0.83}\n",
      "\t\t {'tr_acc': 93.0, 'te_acc': 93.116, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.48, 'te_acc': 93.596, 'th': 0.88}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.32, 'te_acc': 93.27600000000001, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.26, 'te_acc': 93.296, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.36, 'te_acc': 93.34, 'th': 0.75}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.428, 'th': 0.76}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.428, 'th': 0.76}\n",
      "\t\t {'tr_acc': 93.4, 'te_acc': 93.41199999999999, 'th': 0.76}\n",
      "\n",
      "\n",
      "Base: model_{4}\n",
      "\t\t {'tr_acc': 89.78, 'te_acc': 89.676, 'th': 0.94}\n",
      "\t\t {'tr_acc': 90.66, 'te_acc': 90.436, 'th': 0.93}\n",
      "\t\t {'tr_acc': 92.74, 'te_acc': 92.572, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 91.08, 'te_acc': 90.80799999999999, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.42, 'te_acc': 93.07600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.96, 'te_acc': 93.05600000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 93.12, 'te_acc': 93.128, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.56, 'te_acc': 92.56400000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.56, 'te_acc': 92.56400000000001, 'th': 0.99}\n",
      "\t\t {'tr_acc': 92.2, 'te_acc': 92.032, 'th': 0.99}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xla_tests = [True, False]\n",
    "for i in range(2):\n",
    "    for xla_mode in xla_tests:\n",
    "        start_time = time.time()\n",
    "        results = train_predictor(xla=xla_mode)\n",
    "        finish_time = time.time()\n",
    "\n",
    "        trials.append(results)\n",
    "        durations.append(finish_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7866bd82-1468-49cf-b3bf-49f24d4d9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(d):\n",
    "    L = [v for k, v in d.items()]\n",
    "    return L\n",
    "\n",
    "# Convert result dictionaries to lists\n",
    "for k, t in enumerate(trials):\n",
    "    for i in range(len(trials[k])):\n",
    "        for j, m in enumerate(trials[k][i]):\n",
    "        #     for k, v in m.items():\n",
    "            if type(m) is dict:\n",
    "                trials[k][i][j] = to_list(m)\n",
    "            for j2, m2 in enumerate(m):\n",
    "                if type(m2) is dict:\n",
    "                    trials[k][i][j][j2] = to_list(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5397d6fe-5876-4f94-92f4-b479bf4f2aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": [
       [
        [
         [
          90.70000052452087,
          90.58800000000001
         ],
         [
          93.32000017166138,
          93.56400000000001
         ],
         [
          90.10000228881836,
          89.88000000000001
         ],
         [
          93.48000288009644,
          93.632
         ],
         [
          91.10000133514404,
          91.01599999999999
         ],
         [
          93.27999949455261,
          93.568
         ],
         [
          93.80000233650208,
          93.88
         ],
         [
          91.28000140190125,
          91.25999999999999
         ],
         [
          93.68000030517578,
          93.748
         ],
         [
          93.41999888420105,
          93.716
         ],
         [
          93.77999901771545,
          93.72399999999999
         ]
        ],
        [
         [
          [
           90.75999999999999,
           90.324
          ],
          [
           90.75999999999999,
           90.324
          ],
          [
           90.75999999999999,
           90.324
          ]
         ],
         [
          [
           93.7,
           93.512
          ],
          [
           93.7,
           93.512
          ],
          [
           93.7,
           93.512
          ]
         ],
         [
          [
           90.24,
           89.812
          ],
          [
           90.24,
           89.812
          ],
          [
           90.24,
           89.812
          ]
         ],
         [
          [
           93.04,
           93.508
          ],
          [
           93.04,
           93.508
          ],
          [
           93.04,
           93.508
          ]
         ],
         [
          [
           90.92,
           91.10000000000001
          ],
          [
           90.92,
           91.10000000000001
          ],
          [
           90.92,
           91.10000000000001
          ]
         ],
         [
          [
           92.66,
           92.92399999999999
          ],
          [
           92.66,
           92.92399999999999
          ],
          [
           92.66,
           92.92399999999999
          ]
         ],
         [
          [
           93.36,
           93.616
          ],
          [
           92.64,
           92.864
          ],
          [
           92.64,
           92.864
          ],
          [
           92.2,
           92.144
          ]
         ],
         [
          [
           91.3,
           91.18
          ],
          [
           90.86,
           91.06400000000001
          ],
          [
           90.86,
           91.06400000000001
          ],
          [
           90.60000000000001,
           90.668
          ]
         ],
         [
          [
           93.17999999999999,
           93.144
          ],
          [
           92.2,
           92.252
          ],
          [
           92.2,
           92.252
          ],
          [
           91.84,
           91.724
          ]
         ],
         [
          [
           92.82000000000001,
           93.33200000000001
          ],
          [
           92.86,
           92.896
          ],
          [
           92.86,
           92.896
          ],
          [
           92.47999999999999,
           92.528
          ]
         ],
         [
          [
           93.02,
           93.364
          ],
          [
           92.80000000000001,
           92.84400000000001
          ],
          [
           92.80000000000001,
           92.84400000000001
          ]
         ]
        ],
        [
         [
          [
           90.44,
           90.064,
           0.92
          ],
          [
           93.08,
           92.624,
           0.95
          ],
          [
           89.8,
           89.44800000000001,
           0.89
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.86,
           93.28,
           0.99
          ],
          [
           92.88,
           92.88,
           0.99
          ],
          [
           92.88,
           92.88,
           0.99
          ],
          [
           92.62,
           92.524,
           0.99
          ]
         ],
         [
          [
           90.28,
           90.076,
           0.82
          ],
          [
           92.72,
           92.708,
           0.97
          ],
          [
           90.9,
           90.672,
           0.84
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           93.02,
           93.144,
           0.99
          ],
          [
           92.32,
           92.376,
           0.97
          ],
          [
           92.32,
           92.376,
           0.97
          ],
          [
           92.06,
           91.988,
           0.97
          ]
         ],
         [
          [
           93.36,
           93.416,
           0.83
          ],
          [
           93.38,
           93.352,
           0.83
          ],
          [
           93,
           93.116,
           0.75
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.36,
           93.34,
           0.75
          ],
          [
           93.4,
           93.428,
           0.76
          ],
          [
           93.4,
           93.428,
           0.76
          ],
          [
           93.4,
           93.41199999999999,
           0.76
          ]
         ],
         [
          [
           89.78,
           89.676,
           0.94
          ],
          [
           90.66,
           90.436,
           0.93
          ],
          [
           92.74,
           92.572,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           93.12,
           93.128,
           0.99
          ],
          [
           92.56,
           92.56400000000001,
           0.99
          ],
          [
           92.56,
           92.56400000000001,
           0.99
          ],
          [
           92.2,
           92.032,
           0.99
          ]
         ]
        ]
       ],
       [
        [
         [
          90.70000052452087,
          90.57600000000001
         ],
         [
          93.30000281333923,
          93.58800000000001
         ],
         [
          90.02000093460083,
          89.89200000000001
         ],
         [
          93.50000023841858,
          93.676
         ],
         [
          91.07999801635742,
          91.01599999999999
         ],
         [
          93.26000213623047,
          93.592
         ],
         [
          93.80000233650208,
          93.904
         ],
         [
          91.28000140190125,
          91.268
         ],
         [
          93.68000030517578,
          93.748
         ],
         [
          93.37999820709229,
          93.728
         ],
         [
          93.77999901771545,
          93.652
         ]
        ],
        [
         [
          [
           90.75999999999999,
           90.324
          ],
          [
           90.75999999999999,
           90.324
          ],
          [
           90.75999999999999,
           90.324
          ]
         ],
         [
          [
           93.7,
           93.512
          ],
          [
           93.7,
           93.512
          ],
          [
           93.7,
           93.512
          ]
         ],
         [
          [
           90.24,
           89.812
          ],
          [
           90.24,
           89.812
          ],
          [
           90.24,
           89.812
          ]
         ],
         [
          [
           93.04,
           93.508
          ],
          [
           93.04,
           93.508
          ],
          [
           93.04,
           93.508
          ]
         ],
         [
          [
           90.92,
           91.10000000000001
          ],
          [
           90.92,
           91.10000000000001
          ],
          [
           90.92,
           91.10000000000001
          ]
         ],
         [
          [
           92.66,
           92.92399999999999
          ],
          [
           92.66,
           92.92399999999999
          ],
          [
           92.66,
           92.92399999999999
          ]
         ],
         [
          [
           93.36,
           93.616
          ],
          [
           92.64,
           92.864
          ],
          [
           92.64,
           92.864
          ],
          [
           92.2,
           92.144
          ]
         ],
         [
          [
           91.3,
           91.18
          ],
          [
           90.86,
           91.06400000000001
          ],
          [
           90.86,
           91.06400000000001
          ],
          [
           90.60000000000001,
           90.668
          ]
         ],
         [
          [
           93.17999999999999,
           93.144
          ],
          [
           92.2,
           92.252
          ],
          [
           92.2,
           92.252
          ],
          [
           91.84,
           91.724
          ]
         ],
         [
          [
           92.82000000000001,
           93.33200000000001
          ],
          [
           92.86,
           92.896
          ],
          [
           92.86,
           92.896
          ],
          [
           92.47999999999999,
           92.528
          ]
         ],
         [
          [
           93.02,
           93.364
          ],
          [
           92.80000000000001,
           92.84400000000001
          ],
          [
           92.80000000000001,
           92.84400000000001
          ]
         ]
        ],
        [
         [
          [
           90.44,
           90.064,
           0.92
          ],
          [
           93.08,
           92.624,
           0.95
          ],
          [
           89.8,
           89.44800000000001,
           0.89
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.86,
           93.28,
           0.99
          ],
          [
           92.88,
           92.88,
           0.99
          ],
          [
           92.88,
           92.88,
           0.99
          ],
          [
           92.62,
           92.524,
           0.99
          ]
         ],
         [
          [
           90.28,
           90.076,
           0.82
          ],
          [
           92.72,
           92.708,
           0.97
          ],
          [
           90.9,
           90.672,
           0.84
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           93.02,
           93.144,
           0.99
          ],
          [
           92.32,
           92.376,
           0.97
          ],
          [
           92.32,
           92.376,
           0.97
          ],
          [
           92.06,
           91.988,
           0.97
          ]
         ],
         [
          [
           93.36,
           93.416,
           0.83
          ],
          [
           93.38,
           93.352,
           0.83
          ],
          [
           93,
           93.116,
           0.75
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.36,
           93.34,
           0.75
          ],
          [
           93.4,
           93.428,
           0.76
          ],
          [
           93.4,
           93.428,
           0.76
          ],
          [
           93.4,
           93.41199999999999,
           0.76
          ]
         ],
         [
          [
           89.78,
           89.676,
           0.94
          ],
          [
           90.66,
           90.436,
           0.93
          ],
          [
           92.74,
           92.572,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           93.12,
           93.128,
           0.99
          ],
          [
           92.56,
           92.56400000000001,
           0.99
          ],
          [
           92.56,
           92.56400000000001,
           0.99
          ],
          [
           92.2,
           92.032,
           0.99
          ]
         ]
        ]
       ],
       [
        [
         [
          90.71999788284302,
          90.568
         ],
         [
          93.30000281333923,
          93.60000000000001
         ],
         [
          90.03999829292297,
          89.88000000000001
         ],
         [
          93.50000023841858,
          93.636
         ],
         [
          91.10000133514404,
          91.00399999999999
         ],
         [
          93.27999949455261,
          93.568
         ],
         [
          93.73999834060669,
          93.872
         ],
         [
          91.25999808311462,
          91.244
         ],
         [
          93.68000030517578,
          93.748
         ],
         [
          93.44000220298767,
          93.732
         ],
         [
          93.77999901771545,
          93.684
         ]
        ],
        [
         [
          [
           90.75999999999999,
           90.324
          ],
          [
           90.75999999999999,
           90.324
          ],
          [
           90.75999999999999,
           90.324
          ]
         ],
         [
          [
           93.7,
           93.512
          ],
          [
           93.7,
           93.512
          ],
          [
           93.7,
           93.512
          ]
         ],
         [
          [
           90.24,
           89.812
          ],
          [
           90.24,
           89.812
          ],
          [
           90.24,
           89.812
          ]
         ],
         [
          [
           93.04,
           93.508
          ],
          [
           93.04,
           93.508
          ],
          [
           93.04,
           93.508
          ]
         ],
         [
          [
           90.92,
           91.10000000000001
          ],
          [
           90.92,
           91.10000000000001
          ],
          [
           90.92,
           91.10000000000001
          ]
         ],
         [
          [
           92.66,
           92.92399999999999
          ],
          [
           92.66,
           92.92399999999999
          ],
          [
           92.66,
           92.92399999999999
          ]
         ],
         [
          [
           93.36,
           93.616
          ],
          [
           92.64,
           92.864
          ],
          [
           92.64,
           92.864
          ],
          [
           92.2,
           92.144
          ]
         ],
         [
          [
           91.3,
           91.18
          ],
          [
           90.86,
           91.06400000000001
          ],
          [
           90.86,
           91.06400000000001
          ],
          [
           90.60000000000001,
           90.668
          ]
         ],
         [
          [
           93.17999999999999,
           93.144
          ],
          [
           92.2,
           92.252
          ],
          [
           92.2,
           92.252
          ],
          [
           91.84,
           91.724
          ]
         ],
         [
          [
           92.82000000000001,
           93.33200000000001
          ],
          [
           92.86,
           92.896
          ],
          [
           92.86,
           92.896
          ],
          [
           92.47999999999999,
           92.528
          ]
         ],
         [
          [
           93.02,
           93.364
          ],
          [
           92.80000000000001,
           92.84400000000001
          ],
          [
           92.80000000000001,
           92.84400000000001
          ]
         ]
        ],
        [
         [
          [
           90.44,
           90.064,
           0.92
          ],
          [
           93.08,
           92.624,
           0.95
          ],
          [
           89.8,
           89.44800000000001,
           0.89
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.86,
           93.28,
           0.99
          ],
          [
           92.88,
           92.88,
           0.99
          ],
          [
           92.88,
           92.88,
           0.99
          ],
          [
           92.62,
           92.524,
           0.99
          ]
         ],
         [
          [
           90.28,
           90.076,
           0.82
          ],
          [
           92.72,
           92.708,
           0.97
          ],
          [
           90.9,
           90.672,
           0.84
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           93.02,
           93.144,
           0.99
          ],
          [
           92.32,
           92.376,
           0.97
          ],
          [
           92.32,
           92.376,
           0.97
          ],
          [
           92.06,
           91.988,
           0.97
          ]
         ],
         [
          [
           93.36,
           93.416,
           0.83
          ],
          [
           93.38,
           93.352,
           0.83
          ],
          [
           93,
           93.116,
           0.75
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.36,
           93.34,
           0.75
          ],
          [
           93.4,
           93.428,
           0.76
          ],
          [
           93.4,
           93.428,
           0.76
          ],
          [
           93.4,
           93.41199999999999,
           0.76
          ]
         ],
         [
          [
           89.78,
           89.676,
           0.94
          ],
          [
           90.66,
           90.436,
           0.93
          ],
          [
           92.74,
           92.572,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           93.12,
           93.128,
           0.99
          ],
          [
           92.56,
           92.56400000000001,
           0.99
          ],
          [
           92.56,
           92.56400000000001,
           0.99
          ],
          [
           92.2,
           92.032,
           0.99
          ]
         ]
        ]
       ],
       [
        [
         [
          90.71999788284302,
          90.568
         ],
         [
          93.30000281333923,
          93.596
         ],
         [
          89.99999761581421,
          89.9
         ],
         [
          93.48000288009644,
          93.636
         ],
         [
          91.06000065803528,
          91.012
         ],
         [
          93.23999881744385,
          93.596
         ],
         [
          93.77999901771545,
          93.848
         ],
         [
          91.28000140190125,
          91.25999999999999
         ],
         [
          93.68000030517578,
          93.748
         ],
         [
          93.4000015258789,
          93.708
         ],
         [
          93.77999901771545,
          93.73599999999999
         ]
        ],
        [
         [
          [
           90.75999999999999,
           90.324
          ],
          [
           90.75999999999999,
           90.324
          ],
          [
           90.75999999999999,
           90.324
          ]
         ],
         [
          [
           93.7,
           93.512
          ],
          [
           93.7,
           93.512
          ],
          [
           93.7,
           93.512
          ]
         ],
         [
          [
           90.24,
           89.812
          ],
          [
           90.24,
           89.812
          ],
          [
           90.24,
           89.812
          ]
         ],
         [
          [
           93.04,
           93.508
          ],
          [
           93.04,
           93.508
          ],
          [
           93.04,
           93.508
          ]
         ],
         [
          [
           90.92,
           91.10000000000001
          ],
          [
           90.92,
           91.10000000000001
          ],
          [
           90.92,
           91.10000000000001
          ]
         ],
         [
          [
           92.66,
           92.92399999999999
          ],
          [
           92.66,
           92.92399999999999
          ],
          [
           92.66,
           92.92399999999999
          ]
         ],
         [
          [
           93.36,
           93.616
          ],
          [
           92.64,
           92.864
          ],
          [
           92.64,
           92.864
          ],
          [
           92.2,
           92.144
          ]
         ],
         [
          [
           91.3,
           91.18
          ],
          [
           90.86,
           91.06400000000001
          ],
          [
           90.86,
           91.06400000000001
          ],
          [
           90.60000000000001,
           90.668
          ]
         ],
         [
          [
           93.17999999999999,
           93.144
          ],
          [
           92.2,
           92.252
          ],
          [
           92.2,
           92.252
          ],
          [
           91.84,
           91.724
          ]
         ],
         [
          [
           92.82000000000001,
           93.33200000000001
          ],
          [
           92.86,
           92.896
          ],
          [
           92.86,
           92.896
          ],
          [
           92.47999999999999,
           92.528
          ]
         ],
         [
          [
           93.02,
           93.364
          ],
          [
           92.80000000000001,
           92.84400000000001
          ],
          [
           92.80000000000001,
           92.84400000000001
          ]
         ]
        ],
        [
         [
          [
           90.44,
           90.064,
           0.92
          ],
          [
           93.08,
           92.624,
           0.95
          ],
          [
           89.8,
           89.44800000000001,
           0.89
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.86,
           93.28,
           0.99
          ],
          [
           92.88,
           92.88,
           0.99
          ],
          [
           92.88,
           92.88,
           0.99
          ],
          [
           92.62,
           92.524,
           0.99
          ]
         ],
         [
          [
           90.28,
           90.076,
           0.82
          ],
          [
           92.72,
           92.708,
           0.97
          ],
          [
           90.9,
           90.672,
           0.84
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           93.02,
           93.144,
           0.99
          ],
          [
           92.32,
           92.376,
           0.97
          ],
          [
           92.32,
           92.376,
           0.97
          ],
          [
           92.06,
           91.988,
           0.97
          ]
         ],
         [
          [
           93.36,
           93.416,
           0.83
          ],
          [
           93.38,
           93.352,
           0.83
          ],
          [
           93,
           93.116,
           0.75
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.36,
           93.34,
           0.75
          ],
          [
           93.4,
           93.428,
           0.76
          ],
          [
           93.4,
           93.428,
           0.76
          ],
          [
           93.4,
           93.41199999999999,
           0.76
          ]
         ],
         [
          [
           89.78,
           89.676,
           0.94
          ],
          [
           90.66,
           90.436,
           0.93
          ],
          [
           92.74,
           92.572,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           93.12,
           93.128,
           0.99
          ],
          [
           92.56,
           92.56400000000001,
           0.99
          ],
          [
           92.56,
           92.56400000000001,
           0.99
          ],
          [
           92.2,
           92.032,
           0.99
          ]
         ]
        ]
       ],
       [
        [
         [
          90.67999720573425,
          90.572
         ],
         [
          93.32000017166138,
          93.56400000000001
         ],
         [
          90.02000093460083,
          89.888
         ],
         [
          93.48000288009644,
          93.632
         ],
         [
          91.00000262260437,
          91.012
         ],
         [
          93.2200014591217,
          93.57600000000001
         ],
         [
          93.76000165939331,
          93.876
         ],
         [
          91.28000140190125,
          91.264
         ],
         [
          93.72000098228455,
          93.752
         ],
         [
          93.4000015258789,
          93.716
         ],
         [
          93.80000233650208,
          93.728
         ]
        ],
        [
         [
          [
           90.75999999999999,
           90.324
          ],
          [
           90.75999999999999,
           90.324
          ],
          [
           90.75999999999999,
           90.324
          ]
         ],
         [
          [
           93.7,
           93.512
          ],
          [
           93.7,
           93.512
          ],
          [
           93.7,
           93.512
          ]
         ],
         [
          [
           90.24,
           89.812
          ],
          [
           90.24,
           89.812
          ],
          [
           90.24,
           89.812
          ]
         ],
         [
          [
           93.04,
           93.508
          ],
          [
           93.04,
           93.508
          ],
          [
           93.04,
           93.508
          ]
         ],
         [
          [
           90.92,
           91.10000000000001
          ],
          [
           90.92,
           91.10000000000001
          ],
          [
           90.92,
           91.10000000000001
          ]
         ],
         [
          [
           92.66,
           92.92399999999999
          ],
          [
           92.66,
           92.92399999999999
          ],
          [
           92.66,
           92.92399999999999
          ]
         ],
         [
          [
           93.36,
           93.616
          ],
          [
           92.64,
           92.864
          ],
          [
           92.64,
           92.864
          ],
          [
           92.2,
           92.144
          ]
         ],
         [
          [
           91.3,
           91.18
          ],
          [
           90.86,
           91.06400000000001
          ],
          [
           90.86,
           91.06400000000001
          ],
          [
           90.60000000000001,
           90.668
          ]
         ],
         [
          [
           93.17999999999999,
           93.144
          ],
          [
           92.2,
           92.252
          ],
          [
           92.2,
           92.252
          ],
          [
           91.84,
           91.724
          ]
         ],
         [
          [
           92.82000000000001,
           93.33200000000001
          ],
          [
           92.86,
           92.896
          ],
          [
           92.86,
           92.896
          ],
          [
           92.47999999999999,
           92.528
          ]
         ],
         [
          [
           93.02,
           93.364
          ],
          [
           92.80000000000001,
           92.84400000000001
          ],
          [
           92.80000000000001,
           92.84400000000001
          ]
         ]
        ],
        [
         [
          [
           90.44,
           90.064,
           0.92
          ],
          [
           93.08,
           92.624,
           0.95
          ],
          [
           89.8,
           89.44800000000001,
           0.89
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           93.18,
           93.27600000000001,
           0.97
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           91.14,
           91.072,
           0.95
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.84,
           92.784,
           0.97
          ],
          [
           92.86,
           93.28,
           0.99
          ],
          [
           92.88,
           92.88,
           0.99
          ],
          [
           92.88,
           92.88,
           0.99
          ],
          [
           92.62,
           92.524,
           0.99
          ]
         ],
         [
          [
           90.28,
           90.076,
           0.82
          ],
          [
           92.72,
           92.708,
           0.97
          ],
          [
           90.9,
           90.672,
           0.84
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           93.42,
           93.408,
           0.99
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           91.14,
           90.924,
           0.95
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           92.7,
           92.892,
           0.98
          ],
          [
           93.02,
           93.144,
           0.99
          ],
          [
           92.32,
           92.376,
           0.97
          ],
          [
           92.32,
           92.376,
           0.97
          ],
          [
           92.06,
           91.988,
           0.97
          ]
         ],
         [
          [
           93.36,
           93.416,
           0.83
          ],
          [
           93.38,
           93.352,
           0.83
          ],
          [
           93,
           93.116,
           0.75
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.48,
           93.596,
           0.88
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.32,
           93.27600000000001,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.26,
           93.296,
           0.75
          ],
          [
           93.36,
           93.34,
           0.75
          ],
          [
           93.4,
           93.428,
           0.76
          ],
          [
           93.4,
           93.428,
           0.76
          ],
          [
           93.4,
           93.41199999999999,
           0.76
          ]
         ],
         [
          [
           89.78,
           89.676,
           0.94
          ],
          [
           90.66,
           90.436,
           0.93
          ],
          [
           92.74,
           92.572,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           91.08,
           90.80799999999999,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           93.42,
           93.07600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           92.96,
           93.05600000000001,
           0.99
          ],
          [
           93.12,
           93.128,
           0.99
          ],
          [
           92.56,
           92.56400000000001,
           0.99
          ],
          [
           92.56,
           92.56400000000001,
           0.99
          ],
          [
           92.2,
           92.032,
           0.99
          ]
         ]
        ]
       ]
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(list(trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742fcd4-1aad-4460-938b-8917b8cda2f4",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb24cdfd-3a9c-4d4b-b6b3-01e8c067420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_scienceplots = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87b4c49d-224e-4bbb-a5be-fc2eaa4f0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = trials[0][0]\n",
    "# print(trials[0][0])\n",
    "\n",
    "l = ['Train', 'Test']\n",
    "combiner_names = [\n",
    "    'Neural Network',\n",
    "    'Bayesian Decision Rule',\n",
    "    'Heuristic-Hybrid'\n",
    "]\n",
    "bdr_props = ['Max', 'Avg', 'Sum', 'Majority']\n",
    "hh_props = l + ['Threshold']\n",
    "label_data = [l, bdr_props, hh_props]\n",
    "\n",
    "# plot_style = 'ggplot'\n",
    "if use_scienceplots:\n",
    "    try:\n",
    "        plt.style.use('science')\n",
    "        plt.style.use(['science','no-latex'])\n",
    "    except:\n",
    "        pass\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def grouped_plot(T=0, C=0, sections=2, reduce=0):\n",
    "    labels = [x.split('_')[-1] for x in get_training_dict('5K').keys()]\n",
    "    values = trials[T][C]\n",
    "#     print(values)\n",
    "#     valshape = np.array(values).shape\n",
    "#     if len(valshape) == 3:\n",
    "#         values\n",
    "\n",
    "    reduced = False\n",
    "    combiner_type = combiner_names[C]\n",
    "    if 'Bayesian' in combiner_type:\n",
    "        for i, v in enumerate(values):\n",
    "            for j, vi in enumerate(v):\n",
    "                if type(vi) in [list, tuple]:\n",
    "                    values[i][j] = vi[reduce]\n",
    "    elif 'Heuristic' in combiner_type:\n",
    "#         print(values)\n",
    "        values = values[reduce]\n",
    "#         print(values)\n",
    "        \n",
    "    if any(g in combiner_type for g in ['Bayesian', 'Heuristic']):\n",
    "        reduced = True\n",
    "    # plt.bar(labels, trials[0][0])\n",
    "\n",
    "    pos = np.arange(len(labels))\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "#     sections = min(len(values[0]), sections)\n",
    "    sections = min(len(label_data[C]), sections)\n",
    "    for n in range(sections):\n",
    "        sections_ = min(len(values[0]), sections)\n",
    "        barwidth = (0.5/sections_)\n",
    "#         V = [x[n] if n <= len(x) else None for x in values]\n",
    "        V = []\n",
    "        for x in values:\n",
    "            try:\n",
    "                V.append(x[n])\n",
    "            except:\n",
    "                V.append(0)\n",
    "#         print(C, n, min(len(label_data[C]), n))\n",
    "        section_labels = label_data[C][min(len(label_data[C])-1, n)]\n",
    "        section_pos = pos+(barwidth*n)\n",
    "#         print(V, section_labels, section_pos, labels)\n",
    "        ax.bar(section_pos, V, barwidth, label=section_labels)\n",
    "\n",
    "#     ticks = pos-(barwidth*sections/4)\n",
    "    ticks = pos+(barwidth*round((sections-2)/2))\n",
    "    # print(ticks)\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(labels)\n",
    "\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.set_xlabel('Contributing Models')\n",
    "    \n",
    "    s = l[reduce] if reduced else ''\n",
    "    title = f'{combiner_names[C]} Combiner | {s} Accuracy by Model'\n",
    "    \n",
    "#         title += ' - '+l[reduce]\n",
    "    ax.set_title(title, pad=30)\n",
    "#     ax.margins(0.5)\n",
    "#     plt.subplots_adjust(left=0.3)\n",
    "\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1))\n",
    "#     fig.tight_layout(pad=1.5)\n",
    "    return ax\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "348d3931-c548-4346-8bcd-d7a01119120e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through the combiner indices and generate the graph for each one\n",
    "for i in range(2):\n",
    "    grouped_plot(T=0, C=i, sections=4, reduce=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0bb0e8-991e-4e9c-a72b-3bf66f06eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\n",
    "    'a': 5,\n",
    "    'b': 35,\n",
    "    'c': 2.8\n",
    "}\n",
    "# plt.plot(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
